# ArtExtract

<div align="center">

![ArtExtract Logo](https://img.shields.io/badge/ArtExtract-Deep%20Learning%20for%20Art%20Analysis-blue?style=for-the-badge)

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9%2B-orange)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

</div>

## ğŸ¨ Project Overview

ArtExtract is an advanced deep learning framework for art analysis that combines computer vision and neural network architectures to understand and classify artistic content. The system employs state-of-the-art CNN-RNN hybrid models to perform two primary tasks:

<div align="center">
<table>
<tr>
<td width="50%">

### ğŸ–¼ï¸ Task 1: Style/Artist/Genre Classification

- **Architecture**: CNN-RNN hybrid with attention mechanisms
- **Dataset**: ArtGAN WikiArt collection (80,000+ paintings)
- **Features**:
  - Multiple CNN backbones (ResNet, EfficientNet)
  - Bidirectional RNN layers (LSTM/GRU)
  - Attention for focusing on artistic elements
  - Comprehensive outlier detection
  - Robust evaluation metrics

</td>
<td width="50%">

### ğŸ” Task 2: Painting Similarity Detection

- **Architecture**: Feature extraction + similarity indexing
- **Dataset**: National Gallery of Art collection
- **Features**:
  - Deep feature extraction (CNN/CLIP)
  - Multiple similarity metrics
  - Faiss indexing for efficient search
  - Interactive visualization
  - Comprehensive evaluation framework

</td>
</tr>
</table>
</div>

## ğŸ—ï¸ Architecture

<div align="center">

### System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ArtExtract System                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Style/Artist Classification â”‚     Painting Similarity Detection  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚      CNN Backbone       â”‚ â”‚ â”‚    Feature Extraction       â”‚   â”‚
â”‚ â”‚  ResNet/EfficientNet    â”‚ â”‚ â”‚    CNN/CLIP Models          â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â–¼               â”‚             â–¼                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚   Feature Processing    â”‚ â”‚ â”‚    Similarity Computation    â”‚   â”‚
â”‚ â”‚  Attention Mechanism    â”‚ â”‚ â”‚    Cosine/Faiss Index        â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â–¼               â”‚             â–¼                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚      RNN Layers         â”‚ â”‚ â”‚      Ranking Engine          â”‚   â”‚
â”‚ â”‚   LSTM/GRU/Bidirectionalâ”‚ â”‚ â”‚      Top-K Results           â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â–¼               â”‚             â–¼                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚   Classification Head   â”‚ â”‚ â”‚    Interactive Results       â”‚   â”‚
â”‚ â”‚   Style/Artist/Genre    â”‚ â”‚ â”‚    Visualization UI          â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CNN-RNN Classification Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Style/Artist/Genre Classification System              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           â”‚             â”‚                â”‚                â”‚             â”‚
â”‚  Input    â”‚    CNN      â”‚   Feature      â”‚     RNN        â”‚  Output     â”‚
â”‚  Image    â”‚  Backbone   â”‚   Processing   â”‚    Layer       â”‚  Classes    â”‚
â”‚           â”‚             â”‚                â”‚                â”‚             â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚            â”‚               â”‚                â”‚              â”‚
      â–¼            â–¼               â–¼                â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 224x224  â”‚ â”‚â€¢ ResNet50    â”‚ â”‚â€¢ Spatial     â”‚ â”‚â€¢ LSTM/GRU    â”‚ â”‚â€¢ Style  â”‚
â”‚ RGB      â”‚ â”‚â€¢ ResNet18    â”‚ â”‚  Features    â”‚ â”‚â€¢ Bidirectionalâ”‚ â”‚â€¢ Artist â”‚
â”‚ Artwork  â”‚ â”‚â€¢ EfficientNetâ”‚ â”‚â€¢ Attention   â”‚ â”‚â€¢ Attention   â”‚ â”‚â€¢ Genre  â”‚
â”‚ Image    â”‚ â”‚â€¢ MobileNetV2 â”‚ â”‚  Mechanism   â”‚ â”‚  Weights     â”‚ â”‚â€¢ Softmaxâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Painting Similarity Detection System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Painting Similarity Detection System                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚           â”‚             â”‚                â”‚                â”‚             â”‚
â”‚  Query    â”‚  Feature    â”‚   Similarity   â”‚    Ranking     â”‚  Retrieved  â”‚
â”‚  Painting â”‚  Extraction â”‚   Computation  â”‚    Engine      â”‚  Paintings  â”‚
â”‚           â”‚             â”‚                â”‚                â”‚             â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚            â”‚               â”‚                â”‚              â”‚
      â–¼            â–¼               â–¼                â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Input    â”‚ â”‚â€¢ ResNet50    â”‚ â”‚â€¢ Cosine      â”‚ â”‚â€¢ Top-K       â”‚ â”‚â€¢ Similar â”‚
â”‚ Artwork  â”‚ â”‚â€¢ VGG16       â”‚ â”‚  Similarity  â”‚ â”‚  Results     â”‚ â”‚  Artwork â”‚
â”‚ Image    â”‚ â”‚â€¢ CLIP        â”‚ â”‚â€¢ Faiss Index â”‚ â”‚â€¢ Confidence  â”‚ â”‚â€¢ Ranked  â”‚
â”‚          â”‚ â”‚â€¢ Custom      â”‚ â”‚â€¢ L2 Distance â”‚ â”‚  Scores      â”‚ â”‚  Results â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Feature     â”‚
        â”‚  Database    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

## ğŸ”§ Technical Implementation

### CNN-RNN Classification Model

The CNN-RNN classification model combines the spatial feature extraction capabilities of CNNs with the sequential modeling power of RNNs:

1. **CNN Backbone**: Extracts rich visual features from artwork images
   - Supports multiple architectures: ResNet50/18, EfficientNet-B0, MobileNetV2
   - Pretrained on ImageNet and fine-tuned on art datasets
   - Outputs feature maps that capture artistic elements

2. **Feature Processing**: Transforms CNN features for RNN consumption
   - Reshapes spatial features to sequential format
   - Optional attention mechanism to focus on discriminative regions
   - Maintains spatial relationships in feature representation

3. **RNN Layer**: Processes sequential information in the feature maps
   - LSTM or GRU cells with optional bidirectional processing
   - Captures temporal and spatial relationships between features
   - Attention mechanism for highlighting important features

4. **Classification Layer**: Produces final style/artist/genre predictions
   - Fully-connected layer with softmax activation
   - Multi-class classification with confidence scores
   - Optional outlier detection for identifying unusual artwork

### Outlier Detection

The system implements multiple outlier detection methods to identify paintings that don't fit their assigned categories:

1. **Isolation Forest**: Unsupervised algorithm that isolates observations by randomly selecting features
2. **Local Outlier Factor**: Measures the local deviation of density of a sample with respect to its neighbors
3. **Autoencoder-based Detection**: Neural network trained to reconstruct input data, where outliers have higher reconstruction error

### Painting Similarity System

The similarity detection system finds paintings with similar visual characteristics:

1. **Feature Extraction**: Extracts deep features from paintings
   - CNN-based extraction using ResNet, VGG16, or EfficientNet
   - CLIP-based extraction for semantic understanding
   - Produces high-dimensional feature vectors (2048-dim)

2. **Similarity Index**: Efficiently computes similarity between paintings
   - Faiss index for fast approximate nearest neighbor search
   - Supports different distance metrics (L2, inner product, cosine)
   - GPU acceleration for large-scale similarity computation

3. **Similarity Retrieval**: Finds and ranks similar paintings
   - Retrieves top-K most similar paintings
   - Ranks results by similarity score
   - Interactive visualization of similar artwork

## ğŸ“ Project Structure

```
ArtExtract/
â”œâ”€â”€ data/                             # Data storage and preprocessing
â”‚   â”œâ”€â”€ preprocessing/                # Scripts for data loading and preprocessing
â”‚   â””â”€â”€ README.md                     # Data documentation
â”‚
â”œâ”€â”€ models/                           # Model implementations
â”‚   â”œâ”€â”€ style_classification/         # CNN-RNN models for classification
â”‚   â”‚   â”œâ”€â”€ cnn_rnn_model.py          # CNN-RNN architecture implementation
â”‚   â”‚   â”œâ”€â”€ outlier_detection.py      # Outlier detection methods
â”‚   â”‚   â”œâ”€â”€ train_wikiart_refined.py  # Training script for WikiArt dataset
â”‚   â”‚   â””â”€â”€ test_train.py             # Testing and evaluation script
â”‚   â”‚
â”‚   â”œâ”€â”€ similarity_detection/         # Similarity models
â”‚   â”‚   â”œâ”€â”€ feature_extraction.py     # Feature extraction from paintings
â”‚   â”‚   â”œâ”€â”€ similarity_model.py       # Similarity model implementations
â”‚   â”‚   â”œâ”€â”€ train_similarity_model.py # Training script for similarity models
â”‚   â”‚   â””â”€â”€ demo_similarity.py        # Demo script for similarity detection
â”‚   â”‚
â”‚   â””â”€â”€ utils.py                      # Shared utilities
â”‚
â”œâ”€â”€ demo/                             # Interactive demo applications
â”‚   â””â”€â”€ demo_app.py                   # Gradio-based demo interface
â”‚
â”œâ”€â”€ evaluation/                       # Evaluation metrics and scripts
â”‚   â”œâ”€â”€ classification_metrics.py     # Metrics for classification task
â”‚   â”œâ”€â”€ similarity_metrics.py         # Metrics for similarity detection task
â”‚   â””â”€â”€ visualization.py              # Visualization utilities
â”‚
â”œâ”€â”€ notebooks/                        # Jupyter notebooks for exploration
â”‚   â””â”€â”€ similarity_detection_demo.ipynb  # Demo notebook for similarity detection
â”‚
â”œâ”€â”€ ArtExtract_Project_Report.md      # Detailed project report
â”œâ”€â”€ requirements.txt                  # Project dependencies
â””â”€â”€ README.md                         # Project documentation
```

## ğŸ”„ Data Flow

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input Data  â”‚â”€â”€â”€â”€â–¶â”‚ Preprocessingâ”‚â”€â”€â”€â”€â–¶â”‚Model Trainingâ”‚â”€â”€â”€â”€â–¶â”‚  Validation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚Visualization â”‚â—€â”€â”€â”€â”€â”‚   Results    â”‚â—€â”€â”€â”€â”€â”‚  Inference   â”‚â—€â”€â”€â”€â”€â”‚Trained Modelsâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

</div>

## ğŸš€ Setup and Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/ArtExtract.git
   cd ArtExtract
   ```

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Download the datasets:
   - ArtGAN WikiArt dataset: https://github.com/cs-chan/ArtGAN/blob/master/WikiArt%20Dataset/README.md
   - National Gallery of Art dataset: https://github.com/NationalGalleryOfArt/opendata

4. Prepare data:
   ```bash
   python data/preprocessing/extract_wikiart.py --dataset wikiart --output_dir data/wikiart_refined
   ```

## ğŸ’» Usage

### Style/Artist/Genre Classification

Use the CNN-RNN model for art classification:

```python
from models.style_classification.cnn_rnn_model import CNNRNNModel

# Initialize model
model = CNNRNNModel(
    num_classes=10,
    cnn_backbone='resnet50',
    rnn_type='lstm',
    bidirectional=True,
    use_attention=True
)

# Load pre-trained weights
model.load_weights('path/to/weights.pth')

# Predict on an image
import cv2
import numpy as np

img = cv2.imread('path/to/artwork.jpg')
img = cv2.resize(img, (224, 224))
img = img / 255.0  # normalize
img = np.expand_dims(img, axis=0)  # add batch dimension

predictions = model.predict(img)
```

### Outlier Detection

Detect outliers in your dataset:

```python
from models.style_classification.outlier_detection import IsolationForestDetector

# Initialize detector
detector = IsolationForestDetector()

# Fit detector on features
detector.fit(features)

# Get outlier indices
outlier_indices = detector.get_outlier_indices(features)

# Visualize outliers
from models.style_classification.outlier_detection import visualize_outliers
visualize_outliers(features, labels, outlier_indices, class_names)
```

### Painting Similarity Detection

Extract features from paintings:

```python
from models.similarity_detection.feature_extraction import FeatureExtractor

# Initialize feature extractor (options: 'resnet50', 'vgg16', 'clip')
extractor = FeatureExtractor(model_type='resnet50')

# Extract features from an image
features = extractor.extract_features_from_image(image)

# Extract features from a directory of images
features_dict = extractor.extract_features_from_directory('path/to/images/')
```

Find similar paintings using the similarity model:

```python
from models.similarity_detection.similarity_model import (
    create_similarity_model,
    PaintingSimilaritySystem
)

# Create similarity model (options: 'cosine', 'faiss')
similarity_model = create_similarity_model('faiss', feature_dim=2048)

# Create painting similarity system
similarity_system = PaintingSimilaritySystem(
    similarity_model=similarity_model,
    features=features,
    image_paths=image_paths
)

# Find similar paintings
result = similarity_system.find_similar_paintings(query_idx=0, k=5)
```

### Running the Demo

Run the interactive demo application:

```bash
python demo/demo_app.py --model_path path/to/model --interactive
```

## ğŸ“Š Evaluation Metrics

### Classification Metrics

The classification models are evaluated using:
- **Accuracy**: Overall correctness of predictions
- **Precision & Recall**: Measure of exactness and completeness
- **F1 Score**: Harmonic mean of precision and recall
- **Confusion Matrix**: Detailed breakdown of classification performance
- **ROC Curve and AUC**: Performance across different thresholds

### Similarity Metrics

The similarity models are evaluated using:
- **Precision@k**: Precision of the top-k retrieved results
- **Mean Average Precision (MAP)**: Overall precision across all queries
- **Normalized Discounted Cumulative Gain (NDCG)**: Ranking quality measure
- **User Studies**: Human evaluation of similarity results

## ğŸ“ˆ Visualization

ArtExtract includes comprehensive visualization tools:

1. **Training Visualization**: Loss and accuracy curves during training
2. **Confusion Matrix**: Visual representation of classification performance
3. **Feature Space Visualization**: t-SNE and PCA projections of learned features
4. **Outlier Visualization**: Identification of paintings that don't fit their categories
5. **Similarity Visualization**: Interactive display of similar paintings

## ğŸ”® Future Work

We are actively working on enhancing ArtExtract with:
- Transformer-based architectures (Vision Transformer)
- Multi-modal models combining image and textual descriptions
- Self-supervised learning approaches for improved feature extraction
- Style transfer capabilities
- Interactive web application for art exploration

## ğŸ“š Citation

If you use ArtExtract in your research, please cite:

```
@software{ArtExtract2023,
  author = {Your Name},
  title = {ArtExtract: Deep Learning for Art Classification and Similarity Detection},
  year = {2023},
  url = {https://github.com/yourusername/ArtExtract}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
