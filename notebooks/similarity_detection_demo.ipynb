{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Painting Similarity Detection Demo\n",
    "\n",
    "This notebook demonstrates how to use the painting similarity detection model in the ArtExtract project. We'll cover:\n",
    "\n",
    "1. Feature extraction from paintings\n",
    "2. Building a similarity model\n",
    "3. Finding similar paintings\n",
    "4. Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# Import project modules\n",
    "from models.similarity_detection.feature_extraction import FeatureExtractor\n",
    "from models.similarity_detection.similarity_model import (\n",
    "    create_similarity_model,\n",
    "    PaintingSimilaritySystem,\n",
    "    CosineSimilarityModel,\n",
    "    FaissIndexModel\n",
    ")\n",
    "from evaluation.similarity_metrics import SimilarityEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "First, let's set up our configuration for the demo. You'll need to adjust the paths to point to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_DIR = \"../data/national_gallery\"  # Change this to your dataset directory\n",
    "OUTPUT_DIR = \"../output/similarity_demo\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Feature extraction configuration\n",
    "FEATURE_EXTRACTOR_TYPE = \"resnet50\"  # Options: \"resnet50\", \"efficientnet\", \"clip\"\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Similarity model configuration\n",
    "SIMILARITY_MODEL_TYPE = \"faiss\"  # Options: \"cosine\", \"faiss\"\n",
    "INDEX_TYPE = \"L2\"  # Options: \"L2\", \"IP\", \"Cosine\"\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "\n",
    "# Number of similar paintings to retrieve\n",
    "K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load or Create Dataset\n",
    "\n",
    "We need a dataset of paintings to work with. For this demo, we'll load images from a directory and create a simple metadata DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from a directory\n",
    "def load_images_from_directory(directory):\n",
    "    \"\"\"Load images from a directory.\"\"\"\n",
    "    image_paths = []\n",
    "    metadata = []\n",
    "    \n",
    "    # Get all image files\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(root, file)\n",
    "                image_paths.append(image_path)\n",
    "                \n",
    "                # Extract simple metadata from path\n",
    "                filename = os.path.basename(image_path)\n",
    "                parent_dir = os.path.basename(os.path.dirname(image_path))\n",
    "                \n",
    "                metadata.append({\n",
    "                    'filename': filename,\n",
    "                    'category': parent_dir,\n",
    "                    'image_path': image_path\n",
    "                })\n",
    "    \n",
    "    # Create metadata DataFrame\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    \n",
    "    print(f\"Loaded {len(image_paths)} images from {directory}\")\n",
    "    \n",
    "    return image_paths, metadata_df\n",
    "\n",
    "# Load images\n",
    "try:\n",
    "    image_paths, metadata_df = load_images_from_directory(DATA_DIR)\n",
    "    \n",
    "    # Display first few rows of metadata\n",
    "    display(metadata_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading images: {e}\")\n",
    "    print(\"For this demo, let's create a dummy dataset with some sample images.\")\n",
    "    \n",
    "    # Create dummy dataset with sample images\n",
    "    # This is just for demonstration purposes\n",
    "    image_paths = []\n",
    "    metadata = []\n",
    "    \n",
    "    # You can replace these with actual image paths\n",
    "    sample_images = [\n",
    "        \"../data/sample/portrait1.jpg\",\n",
    "        \"../data/sample/portrait2.jpg\",\n",
    "        \"../data/sample/landscape1.jpg\",\n",
    "        \"../data/sample/landscape2.jpg\",\n",
    "        \"../data/sample/abstract1.jpg\"\n",
    "    ]\n",
    "    \n",
    "    for i, image_path in enumerate(sample_images):\n",
    "        category = \"portrait\" if \"portrait\" in image_path else \"landscape\" if \"landscape\" in image_path else \"abstract\"\n",
    "        \n",
    "        image_paths.append(image_path)\n",
    "        metadata.append({\n",
    "            'filename': os.path.basename(image_path),\n",
    "            'category': category,\n",
    "            'image_path': image_path\n",
    "        })\n",
    "    \n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    print(f\"Created dummy dataset with {len(image_paths)} sample images\")\n",
    "    display(metadata_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Extraction\n",
    "\n",
    "Now we'll extract features from the paintings using a pre-trained CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature extractor\n",
    "feature_extractor = FeatureExtractor(model_type=FEATURE_EXTRACTOR_TYPE)\n",
    "print(f\"Created {FEATURE_EXTRACTOR_TYPE} feature extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from images\n",
    "features_file = os.path.join(OUTPUT_DIR, f\"{FEATURE_EXTRACTOR_TYPE}_features.pkl\")\n",
    "\n",
    "# Check if features file already exists\n",
    "if os.path.exists(features_file):\n",
    "    print(f\"Loading features from {features_file}\")\n",
    "    with open(features_file, 'rb') as f:\n",
    "        features_data = pickle.load(f)\n",
    "    \n",
    "    features = features_data['features']\n",
    "    feature_image_paths = features_data['image_paths']\n",
    "    \n",
    "    # Verify that the loaded features match our image paths\n",
    "    if len(feature_image_paths) != len(image_paths):\n",
    "        print(f\"Warning: Loaded features for {len(feature_image_paths)} images, but we have {len(image_paths)} images\")\n",
    "        print(\"Extracting features again...\")\n",
    "        extract_features = True\n",
    "    else:\n",
    "        extract_features = False\n",
    "else:\n",
    "    print(f\"Features file not found, extracting features...\")\n",
    "    extract_features = True\n",
    "\n",
    "if extract_features:\n",
    "    # Extract features\n",
    "    features = []\n",
    "    valid_image_paths = []\n",
    "    \n",
    "    for i, image_path in enumerate(tqdm(image_paths, desc=\"Extracting features\")):\n",
    "        try:\n",
    "            # Load image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Extract features\n",
    "            feature = feature_extractor.extract_features_from_image(image)\n",
    "            \n",
    "            # Add to lists\n",
    "            features.append(feature)\n",
    "            valid_image_paths.append(image_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting features from {image_path}: {e}\")\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    features = np.vstack(features)\n",
    "    \n",
    "    # Save features\n",
    "    with open(features_file, 'wb') as f:\n",
    "        pickle.dump({'features': features, 'image_paths': valid_image_paths}, f)\n",
    "    \n",
    "    print(f\"Extracted features for {len(valid_image_paths)} images\")\n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    \n",
    "    # Update image paths and metadata\n",
    "    image_paths = valid_image_paths\n",
    "    metadata_df = metadata_df[metadata_df['image_path'].isin(valid_image_paths)].reset_index(drop=True)\n",
    "else:\n",
    "    print(f\"Loaded features for {len(feature_image_paths)} images\")\n",
    "    print(f\"Features shape: {features.shape}\")\n",
    "    \n",
    "    # Update image paths and metadata\n",
    "    image_paths = feature_image_paths\n",
    "    metadata_df = metadata_df[metadata_df['image_path'].isin(feature_image_paths)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build Similarity Model\n",
    "\n",
    "Now we'll build a similarity model using the extracted features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create similarity model\n",
    "if SIMILARITY_MODEL_TYPE == 'faiss':\n",
    "    # Get feature dimension\n",
    "    feature_dim = features.shape[1]\n",
    "    \n",
    "    # Create Faiss model\n",
    "    similarity_model = create_similarity_model(\n",
    "        'faiss',\n",
    "        feature_dim=feature_dim,\n",
    "        index_type=INDEX_TYPE,\n",
    "        use_gpu=USE_GPU\n",
    "    )\n",
    "else:\n",
    "    # Create cosine similarity model\n",
    "    similarity_model = create_similarity_model('cosine')\n",
    "\n",
    "print(f\"Created {SIMILARITY_MODEL_TYPE} similarity model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create painting similarity system\n",
    "similarity_system = PaintingSimilaritySystem(\n",
    "    similarity_model=similarity_model,\n",
    "    features=features,\n",
    "    image_paths=image_paths,\n",
    "    metadata=metadata_df\n",
    ")\n",
    "\n",
    "print(f\"Created painting similarity system with {len(image_paths)} paintings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find Similar Paintings\n",
    "\n",
    "Let's find paintings similar to a query painting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a random query painting\n",
    "query_idx = np.random.randint(len(image_paths))\n",
    "print(f\"Selected query painting: {image_paths[query_idx]}\")\n",
    "\n",
    "# Display query painting\n",
    "query_img = Image.open(image_paths[query_idx]).convert('RGB')\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(query_img)\n",
    "plt.title(\"Query Painting\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find similar paintings\n",
    "result = similarity_system.find_similar_paintings(query_idx=query_idx, k=K)\n",
    "\n",
    "# Print similar paintings information\n",
    "print(\"Similar Paintings:\")\n",
    "for i, (path, sim) in enumerate(zip(result['similar_paths'], result['similarities'])):\n",
    "    print(f\"{i+1}. {path} (Similarity: {sim:.3f})\")\n",
    "    \n",
    "    # Print metadata if available\n",
    "    if 'similar_metadata' in result:\n",
    "        metadata = result['similar_metadata'][i]\n",
    "        print(f\"   Category: {metadata.get('category', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similar paintings\n",
    "similarity_system.visualize_similar_paintings(\n",
    "    query_idx=query_idx,\n",
    "    k=K,\n",
    "    figsize=(15, 5),\n",
    "    save_path=os.path.join(OUTPUT_DIR, 'similar_paintings.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Find Similar Paintings for a New Image\n",
    "\n",
    "Now let's try finding similar paintings for a new image that's not in our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find similar paintings for a new image\n",
    "def find_similar_for_new_image(image_path):\n",
    "    \"\"\"Find similar paintings for a new image.\"\"\"\n",
    "    # Load image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    # Extract features\n",
    "    feature = feature_extractor.extract_features_from_image(image)\n",
    "    \n",
    "    # Find similar paintings\n",
    "    result = similarity_system.find_similar_to_new_painting(\n",
    "        query_feature=feature,\n",
    "        query_path=image_path,\n",
    "        k=K\n",
    "    )\n",
    "    \n",
    "    # Display query image\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(image)\n",
    "    plt.title(\"Query Painting\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print similar paintings information\n",
    "    print(\"Similar Paintings:\")\n",
    "    for i, (path, sim) in enumerate(zip(result['similar_paths'], result['similarities'])):\n",
    "        print(f\"{i+1}. {path} (Similarity: {sim:.3f})\")\n",
    "        \n",
    "        # Print metadata if available\n",
    "        if 'similar_metadata' in result:\n",
    "            metadata = result['similar_metadata'][i]\n",
    "            print(f\"   Category: {metadata.get('category', 'N/A')}\")\n",
    "    \n",
    "    # Visualize similar paintings\n",
    "    # Load images\n",
    "    query_img = image\n",
    "    similar_imgs = [Image.open(path).convert('RGB') for path in result['similar_paths']]\n",
    "    \n",
    "    # Get similarities\n",
    "    similarities = result['similarities']\n",
    "    \n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(1, len(similar_imgs) + 1, figsize=(15, 5))\n",
    "    \n",
    "    # Plot query image\n",
    "    axes[0].imshow(query_img)\n",
    "    axes[0].set_title('Query')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Plot similar images\n",
    "    for i, (img, sim) in enumerate(zip(similar_imgs, similarities)):\n",
    "        axes[i + 1].imshow(img)\n",
    "        axes[i + 1].set_title(f'Similarity: {sim:.3f}')\n",
    "        axes[i + 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with a new image\n",
    "# Replace this with the path to your new image\n",
    "new_image_path = \"../data/sample/new_painting.jpg\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(new_image_path):\n",
    "    result = find_similar_for_new_image(new_image_path)\n",
    "else:\n",
    "    print(f\"File not found: {new_image_path}\")\n",
    "    print(\"Using a random image from our database instead\")\n",
    "    \n",
    "    # Use a random image from our database\n",
    "    random_idx = np.random.randint(len(image_paths))\n",
    "    while random_idx == query_idx:  # Make sure it's different from the previous query\n",
    "        random_idx = np.random.randint(len(image_paths))\n",
    "    \n",
    "    new_image_path = image_paths[random_idx]\n",
    "    result = find_similar_for_new_image(new_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save the Similarity Model\n",
    "\n",
    "Let's save the trained similarity model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the similarity system\n",
    "model_path = os.path.join(OUTPUT_DIR, 'painting_similarity_system.pkl')\n",
    "similarity_system.save_system(model_path)\n",
    "print(f\"Saved painting similarity system to {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluate the Similarity Model\n",
    "\n",
    "Let's evaluate the performance of our similarity model using some basic metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluator\n",
    "evaluator = SimilarityEvaluator()\n",
    "\n",
    "# For demonstration purposes, let's create a simple evaluation scenario\n",
    "# We'll use the category information as ground truth\n",
    "# Paintings in the same category are considered relevant to each other\n",
    "\n",
    "# Get unique categories\n",
    "categories = metadata_df['category'].unique()\n",
    "print(f\"Found {len(categories)} unique categories: {categories}\")\n",
    "\n",
    "# Create mapping from category to indices\n",
    "category_to_indices = {}\n",
    "for category in categories:\n",
    "    category_to_indices[category] = metadata_df[metadata_df['category'] == category].index.tolist()\n",
    "\n",
    "# Prepare evaluation data\n",
    "all_relevant_items = []\n",
    "all_recommended_items = []\n",
    "\n",
    "# For each painting, find similar paintings and check if they are in the same category\n",
    "num_eval_samples = min(100, len(image_paths))  # Limit to 100 samples for speed\n",
    "eval_indices = np.random.choice(len(image_paths), num_eval_samples, replace=False)\n",
    "\n",
    "for idx in tqdm(eval_indices, desc=\"Evaluating\"):\n",
    "    # Get category of the query painting\n",
    "    query_category = metadata_df.loc[idx, 'category']\n",
    "    \n",
    "    # Get indices of paintings in the same category (relevant items)\n",
    "    relevant_indices = category_to_indices[query_category]\n",
    "    relevant_indices = [i for i in relevant_indices if i != idx]  # Exclude the query itself\n",
    "    \n",
    "    # Find similar paintings\n",
    "    result = similarity_system.find_similar_paintings(query_idx=idx, k=max(args.k_values))\n",
    "    recommended_indices = result['similar_indices']\n",
    "    \n",
    "    # Add to evaluation data\n",
    "    all_relevant_items.append(relevant_indices)\n",
    "    all_recommended_items.append(recommended_indices)\n",
    "\n",
    "# Evaluate the model\n",
    "k_values = [5, 10, 20]\n",
    "results = evaluator.evaluate_similarity_model(\n",
    "    all_relevant_items=all_relevant_items,\n",
    "    all_recommended_items=all_recommended_items,\n",
    "    k_values=k_values\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"Evaluation results:\")\n",
    "print(f\"MAP: {results['map']:.4f}\")\n",
    "print(f\"MRR: {results['mrr']:.4f}\")\n",
    "for k, precision in results['precision_at_k'].items():\n",
    "    print(f\"{k}: {precision:.4f}\")\n",
    "\n",
    "# Plot precision@k\n",
    "evaluator.plot_precision_at_k(\n",
    "    results=results,\n",
    "    save_path=os.path.join(OUTPUT_DIR, 'precision_at_k.png')\n",
    ")\n",
    "\n",
    "# Save results to JSON\n",
    "evaluator.save_results_to_json(\n",
    "    results=results,\n",
    "    output_path=os.path.join(OUTPUT_DIR, 'evaluation_results.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use the painting similarity detection model in the ArtExtract project. We've covered:\n",
    "\n",
    "1. Feature extraction from paintings using a pre-trained CNN model\n",
    "2. Building a similarity model using the extracted features\n",
    "3. Finding similar paintings for a query painting\n",
    "4. Evaluating the performance of the similarity model\n",
    "\n",
    "This approach can be used to find similar paintings based on visual features, which is useful for art exploration, recommendation systems, and more."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
